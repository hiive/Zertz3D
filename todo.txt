# Zertz3D TODO and Improvement Suggestions

## Code Quality Improvements

### ZertzRenderer
1. Visual indicators for valid moves.

### ZertzBoard

1. Check if vector representation needs to have entire board state.

## Feature Ideas
- Add game statistics tracking
- Network multiplayer support


 Missing Test Coverage:

  1. Marble Supply Fix (just implemented)

  - ❌ No test for: "One marble type empty, others available → cannot use captured marbles"
  - ❌ No test for: "All marbles empty → can use captured marbles"
  - ❌ No test for: Transition from supply to captured marbles

  2. Isolated Regions (partially tested - 7 tests)

  - ✅ Single ring with marble (captured)
  - ✅ Single ring vacant (frozen)
  - ✅ Two rings, all occupied (captured)
  - ✅ Two rings, one vacant (frozen)
  - ❌ Multiple isolated regions in one move (some capturable, some frozen)
  - ❌ What if main board becomes smaller than an isolated region?
  - ❌ Capture action creating isolation

  3. Win Conditions

  - ❌ Win during chain capture
  - ❌ Win immediately after isolated region capture
  - ❌ Board completely full (last player wins)
  - ❌ Player runs out of marbles (opponent wins)

  4. Chain Captures

  - ❌ Long capture sequences (3+ jumps)
  - ❌ Multiple available chain paths (player choice)
  - ❌ CAPTURE_LAYER flag behavior

  5. Edge Cases

  - ❌ No removable rings on full board
  - ❌ Ring removal creating multiple frozen regions simultaneously
  - ❌ Geometric vs adjacency ring removal on edge cases


  ML Notes

Separate Inputs

  Spatial: (L, H, W)  → Conv/Spatial Attention
  Global:  (10,)      → Dense/Global Attention
  Pros:
  - Efficient: No redundancy
  - Flexible architecture:
    - Spatial path: Conv → ResNet → features
    - Global path: Dense → embedding → features
    - Cross-attention: Spatial features attend to global context
  - Better inductive bias: Network knows which is spatial vs global
  - Transformer-ready: Natural for attention mechanisms

  Cons:
  - Network needs two input heads (but this is standard)

  Recommended Implementation

  Keep self.state and self.global_state separate (as they are), but update get_current_state() to return both:

  # In zertz_game.py
  def get_current_state(self):
      """Returns complete observable state for ML.

      Returns:
          dict: {
              'spatial': (L, H, W) array - rings, marbles, history, capture flag
              'global': (10,) array - supply, captured, current player
              'player': int - 1 or -1 for perspective
          }
      """
      return {
          'spatial': np.copy(self.board.state),
          'global': np.copy(self.board.global_state),
          'player': self.get_cur_player_value()
      }

  Example Network Architectures

  With cross-attention:
  # Spatial path
  spatial_features = ResNet(spatial_input)  # → (batch, 256, H, W)

  # Global path
  global_embedding = Dense(global_input)    # → (batch, 64)

  # Cross-attention
  attended = CrossAttention(
      query=spatial_features,  # spatial attends to...
      key_value=global_embedding  # ...global context
  )

  # Policy/Value heads
  policy = PolicyHead(attended)
  value = ValueHead(attended)

  Or simple concatenation:
  spatial_features = ResNet(spatial_input)  # → (batch, 256)
  global_features = Dense(global_input)      # → (batch, 64)
  combined = concat([spatial_features, global_features])
  policy = PolicyHead(combined)

  Bottom Line

  Keep them separate. It's more efficient and gives you architectural flexibility. Just make sure the interface
  (get_current_state()) returns both pieces so ML code has complete observability.
